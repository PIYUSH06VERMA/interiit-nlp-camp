{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a45d31a",
   "metadata": {},
   "source": [
    "### Web Search Agent 3\n",
    "\n",
    "## Validation and Reflection Agent (LLM feedback loop)\n",
    "\n",
    "This agent:\n",
    "- First performs a duckduckgo websearch\n",
    "- Summarizes and evaluates the results with an LLM (groq)\n",
    "- Decides weather to accept these summarized results directly, or reqrie the query, or answer directly using the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f30d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43326c",
   "metadata": {},
   "source": [
    "Defining the `pydantic` datamodel for validation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f034174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676508a4",
   "metadata": {},
   "source": [
    "Defining the duckduckgo search function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81c169b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddg_search(query: str, max_results: int = 5) -> List[SearchResult]:\n",
    "    \"\"\"\n",
    "    Perform a search using the DuckDuckGo Search API.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        with DDGS() as ddgs:\n",
    "            results = ddgs.text(query, region='wt-wt',safesearch='Moderate', max_results=max_results)\n",
    "            lines = []\n",
    "            for r in results:\n",
    "                lines.append(SearchResult(\n",
    "                    title=r[\"title\"],\n",
    "                    url=r[\"href\"],\n",
    "                    snippet=r.get(\"body\", \"\")\n",
    "                ))\n",
    "            if not lines:\n",
    "                lines.append(SearchResult(\n",
    "                    title=\"No results found\",\n",
    "                    url=\"\",\n",
    "                    snippet=\"No relevant information available.\"\n",
    "                ))\n",
    "            return lines\n",
    "    except Exception as e:\n",
    "        return [SearchResult(\n",
    "            title=\"Error\",\n",
    "            url=\"\",\n",
    "            snippet=f\"An error occurred while searching: {str(e)}\"\n",
    "        )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd59e7",
   "metadata": {},
   "source": [
    "### Making the PromptTemplate for the Reflective Chain\n",
    "The prompt asks the LLM to evaluate the search results for relevance and completeness, suggests rewrite if needed, or provides a direct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38b0745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"search_results\"],\n",
    "    template=(\n",
    "        \"You are an expert AI assistant. A user asked: {query}\\n\"\n",
    "        \"Here are the web search results:\\n{search_results}\\n\"\n",
    "        \"If these results adequately answer the question, reply:\\n\"\n",
    "        \"ACCEPT\\n\"\n",
    "        \"If they do not, provide only the rewritten concise technical search query after the word 'REWRITE:' \"\n",
    "        \"without any additional explanation or punctuation.\\n\"\n",
    "        \"If you can answer confidently without further search, reply:\\n\"\n",
    "        \"ANSWER: Your detailed answer here.\\n\"\n",
    "        \"Do not provide any additional text or explanation.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de32a4",
   "metadata": {},
   "source": [
    "initialising the reflection chain using the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ff4abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = REFLECTION_PROMPT\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eeebde",
   "metadata": {},
   "source": [
    "writing a helper function to format the Search Results as text for LLM input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ce1cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(results: List[SearchResult]) -> str:\n",
    "    lines = []\n",
    "    for i, r in enumerate(results, start=1):\n",
    "        if r.snippet:\n",
    "            snippet = r.snippet\n",
    "        else:\n",
    "            snippet = \"No snippet available.\"\n",
    "        if r.url:\n",
    "            url = r.url\n",
    "        else:\n",
    "            url = \"No URL available.\"\n",
    "        lines.append(f\"{i}. Title:{r.title}\\nURL:{url}\\nSnippet:{snippet}\\n\") \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d14243",
   "metadata": {},
   "source": [
    "defining the main agent function (it also includes things like what steps the agent followed before giving the final answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fe6d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_function(user_query: str, max_search_results: int = 5, max_reflections: int = 2) -> str:\n",
    "    current_query = user_query\n",
    "    for attempt in range(max_reflections):\n",
    "        results = ddg_search(query=current_query, max_results=max_search_results)\n",
    "        results_f = format_search_results(results)\n",
    "        message = llm_chain.invoke({\"query\": current_query, \"search_results\": results_f})\n",
    "        reflection_response = message.content.strip()\n",
    "        \n",
    "        # Accept logic\n",
    "        if reflection_response.strip() == \"ACCEPT\":\n",
    "            summary_lines = [f\"{r.title} - {r.url}\" for r in results]\n",
    "            return f\"Search results accepted:\\n\" + \"\\n\".join(summary_lines)\n",
    "        \n",
    "        # Try to extract REWRITE from anywhere in the text\n",
    "        if \"REWRITE:\" in reflection_response:\n",
    "            # Take everything after 'REWRITE:' (if there are multiple, pick the last one)\n",
    "            rewritten_parts = reflection_response.split(\"REWRITE:\")\n",
    "            new_query = rewritten_parts[-1].strip()\n",
    "            current_query = new_query\n",
    "            continue\n",
    "        \n",
    "        # Try to extract ANSWER from anywhere in the text\n",
    "        if \"ANSWER:\" in reflection_response:\n",
    "            answer_parts = reflection_response.split(\"ANSWER:\")\n",
    "            answer = answer_parts[-1].strip()\n",
    "            return answer\n",
    "        \n",
    "        # Otherwise, fallback\n",
    "        return f\"Could not interpret reflection response. Here's the raw output:\\n{reflection_response}\"\n",
    "    return f\"Reflection attempts exhausted. Latest results:\\n\" + format_search_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "021a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_function(user_query: str, max_search_results: int = 5, max_reflections: int = 2) -> str:\n",
    "    current_query = user_query\n",
    "    steps = []\n",
    "    for attempt in range(max_reflections):\n",
    "        steps.append(f\"Step {attempt+1}: Searching with query: '{current_query}'\")\n",
    "        results = ddg_search(query=current_query, max_results=max_search_results)\n",
    "        results_f = format_search_results(results)\n",
    "        \n",
    "        message = llm_chain.invoke({\"query\": current_query, \"search_results\": results_f})\n",
    "        reflection_response = message.content.strip()\n",
    "        steps.append(f\"Reflection Response: {reflection_response}\")\n",
    "\n",
    "        if reflection_response == \"ACCEPT\":\n",
    "            steps.append(\"Action: Accepting current results\")\n",
    "            print(\"\\n\".join(steps))\n",
    "            summary_lines = [f\"{r.title} - {r.url}\" for r in results]\n",
    "            return f\"Search results accepted:\\n\" + \"\\n\".join(summary_lines)\n",
    "        \n",
    "        if \"REWRITE:\" in reflection_response:\n",
    "            rewritten_parts = reflection_response.split(\"REWRITE:\")\n",
    "            new_query = rewritten_parts[-1].strip()\n",
    "            steps.append(f\"Action: Rewriting query to: '{new_query}'\")\n",
    "            current_query = new_query\n",
    "            continue\n",
    "        \n",
    "        if \"ANSWER:\" in reflection_response:\n",
    "            answer_parts = reflection_response.split(\"ANSWER:\")\n",
    "            answer = answer_parts[-1].strip()\n",
    "            steps.append(\"Action: Returning direct answer from LLM\")\n",
    "            print(\"\\n\".join(steps))\n",
    "            return answer\n",
    "        \n",
    "        steps.append(\"Action: Could not interpret response, fallback\")\n",
    "        print(\"\\n\".join(steps))\n",
    "        return f\"Could not interpret reflection response. Here's the raw output:\\n{reflection_response}\"\n",
    "    \n",
    "    steps.append(\"Reflection attempts exhausted.\")\n",
    "    print(\"\\n\".join(steps))\n",
    "    return f\"Reflection attempts exhausted. Latest results:\\n\" + format_search_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd81512",
   "metadata": {},
   "source": [
    "## Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5302a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Searching with query: 'What are popular tourist destinations in India during summer?'\n",
      "Reflection Response: REWRITE: popular summer tourist destinations in India\n",
      "Action: Rewriting query to: 'popular summer tourist destinations in India'\n",
      "Step 2: Searching with query: 'popular summer tourist destinations in India'\n",
      "Reflection Response: ACCEPT\n",
      "Action: Accepting current results\n",
      "Search results accepted:\n",
      "What are some family-friendly summer tourist destinations ... | Medium - https://medium.com/@raindropsresort/what-are-some-family-friendly-summer-tourist-destinations-in-south-india-1b5f14bf5b70\n",
      "Exploring the Best Tourist Destinations in India in... - NYC 360 News - https://www.nyc360news.com/exploring-the-best-tourist-destinations-in-india-in-june-and-july\n",
      "Top 10 places to visit in June in India . [Video] | Top places to travel... - https://in.pinterest.com/pin/top-10-places-to-visit-in-june-in-india-video--338121884554460963/\n",
      "Best Places To Visit In May In India - https://www.travelandleisureasia.com/th/destinations/india/best-places-to-visit-in-may-in-india/\n",
      "India travel guide & inspiration - Lonely Planet | Asia - https://www.lonelyplanet.com/destinations/india\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What are popular tourist destinations in India during summer?\"\n",
    "output = agent_function(test_query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef3fb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Searching with query: 'Compare sparse vs dense retrieval methods for document search in modern NLP systems.'\n",
      "Reflection Response: ANSWER: In modern NLP systems, sparse and dense retrieval methods are two prominent approaches for document search. Sparse retrieval methods typically represent documents and queries using high-dimensional, sparse vectors, often based on term-frequency inverse-document-frequency (TF-IDF) weights. This approach excels in traditional information retrieval tasks, especially when dealing with large document collections, as it can efficiently filter out irrelevant documents.\n",
      "\n",
      "On the other hand, dense retrieval methods utilize low-dimensional, dense vectors, usually learned through neural network-based embedding models. These models capture semantic relationships between words and documents, enabling more accurate matching of queries and documents based on their meanings. Dense embeddings have shown impressive performance in various NLP tasks, including document retrieval, especially for short documents.\n",
      "\n",
      "The key differences between sparse and dense retrieval methods lie in their representation and processing of data. Sparse methods focus on exact keyword matching and are often more efficient in terms of computational resources and indexing. In contrast, dense methods prioritize semantic understanding, which can lead to more accurate search results, especially in scenarios where the query and relevant documents do not share exact keywords.\n",
      "\n",
      "Recent advancements in learned sparse embeddings have narrowed the performance gap between sparse and dense methods. Learned sparse embeddings can achieve up to 2-3 times better retrieval performance than traditional sparse methods, making them a competitive choice for modern NLP applications.\n",
      "\n",
      "Ultimately, the choice between sparse and dense retrieval methods depends on the specific requirements of the application, including the size and nature of the document collection, the complexity of the queries, and the available computational resources. By understanding the strengths and weaknesses of each approach, developers can design more effective document search systems that balance efficiency, accuracy, and semantic understanding.\n",
      "Action: Returning direct answer from LLM\n",
      "In modern NLP systems, sparse and dense retrieval methods are two prominent approaches for document search. Sparse retrieval methods typically represent documents and queries using high-dimensional, sparse vectors, often based on term-frequency inverse-document-frequency (TF-IDF) weights. This approach excels in traditional information retrieval tasks, especially when dealing with large document collections, as it can efficiently filter out irrelevant documents.\n",
      "\n",
      "On the other hand, dense retrieval methods utilize low-dimensional, dense vectors, usually learned through neural network-based embedding models. These models capture semantic relationships between words and documents, enabling more accurate matching of queries and documents based on their meanings. Dense embeddings have shown impressive performance in various NLP tasks, including document retrieval, especially for short documents.\n",
      "\n",
      "The key differences between sparse and dense retrieval methods lie in their representation and processing of data. Sparse methods focus on exact keyword matching and are often more efficient in terms of computational resources and indexing. In contrast, dense methods prioritize semantic understanding, which can lead to more accurate search results, especially in scenarios where the query and relevant documents do not share exact keywords.\n",
      "\n",
      "Recent advancements in learned sparse embeddings have narrowed the performance gap between sparse and dense methods. Learned sparse embeddings can achieve up to 2-3 times better retrieval performance than traditional sparse methods, making them a competitive choice for modern NLP applications.\n",
      "\n",
      "Ultimately, the choice between sparse and dense retrieval methods depends on the specific requirements of the application, including the size and nature of the document collection, the complexity of the queries, and the available computational resources. By understanding the strengths and weaknesses of each approach, developers can design more effective document search systems that balance efficiency, accuracy, and semantic understanding.\n"
     ]
    }
   ],
   "source": [
    "test_query = \"Compare sparse vs dense retrieval methods for document search in modern NLP systems.\"\n",
    "output = agent_function(test_query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8708ce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Searching with query: 'What are the top Bollywood movies released in 2024?'\n",
      "Reflection Response: REWRITE: top bollywood movies 2024 release date and name\n",
      "Action: Rewriting query to: 'top bollywood movies 2024 release date and name'\n",
      "Step 2: Searching with query: 'top bollywood movies 2024 release date and name'\n",
      "Reflection Response: ANSWER: According to the search results, some of the top Bollywood movies of 2024 include Amar Singh Chamkila, and over 30 big-budget movies are scheduled for release in 2024. However, the exact names and release dates of all the movies are not provided in the search results. Some of the upcoming movies mentioned include Dunki, Sam Bahadur, Animal, and Salaar, but these are scheduled for release in December 2023, not 2024. The search results suggest that 2024 will be a blockbuster year for Bollywood with a range of genres, including thrillers and comedies, but do not provide a comprehensive list of the top Bollywood movies of 2024.\n",
      "Action: Returning direct answer from LLM\n",
      "According to the search results, some of the top Bollywood movies of 2024 include Amar Singh Chamkila, and over 30 big-budget movies are scheduled for release in 2024. However, the exact names and release dates of all the movies are not provided in the search results. Some of the upcoming movies mentioned include Dunki, Sam Bahadur, Animal, and Salaar, but these are scheduled for release in December 2023, not 2024. The search results suggest that 2024 will be a blockbuster year for Bollywood with a range of genres, including thrillers and comedies, but do not provide a comprehensive list of the top Bollywood movies of 2024.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the top Bollywood movies released in 2024?\"\n",
    "output = agent_function(query)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
