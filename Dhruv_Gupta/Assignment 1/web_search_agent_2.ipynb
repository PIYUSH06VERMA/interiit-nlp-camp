{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0d0dc6",
   "metadata": {},
   "source": [
    "### Web Search Agent 2.\n",
    "\n",
    "## LangChain tool-based websearch agent with LLM Fallback.\n",
    "\n",
    "This is a huge upgrade over the previous agent because:\n",
    "- DuckduckGo based websearch is now wrapped as a `tool` in langchain.\n",
    "- If the websearch proves to be insufficient or inaccurate, there is a direct fallback to an LLM call (gemini)\n",
    "- Error handling is present, and extensibility to using other tools is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ace84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from ddgs import DDGS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37f066",
   "metadata": {},
   "source": [
    "### Defining the DuckDuckGo Web Search Tool\n",
    "\n",
    "This is wrapped as a LangChain Tool for agent orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91db59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddg_search_tool(query: str) -> str:\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = ddgs.text(query, region=\"wt-wt\", safesearch=\"Moderate\", max_results=5)\n",
    "            lines = []\n",
    "            for r in results:\n",
    "                lines.append(f\"{r['title']}\\n{r['href']}\\n{r.get('body','')}\\n\")\n",
    "            if not lines:\n",
    "                return \"No results found on DuckDuckGo.\"\n",
    "            return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"DuckDuckGo search failed: {str(e)}\"\n",
    "\n",
    "web_search = Tool(\n",
    "    name=\"DuckDuckGo Web Search\",\n",
    "    func=ddg_search_tool,\n",
    "    description=\"Use this tool for web searches. Input should be a concise query.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7ab6c",
   "metadata": {},
   "source": [
    "### Defining the fallback tool to answer using LLM\n",
    "\n",
    "If web search is unhelpful, fallback to answering using the LLM by directly prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a39323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_llm(query: str) -> str:\n",
    "    prompt = f\"Answer the following question in a helpful manner:\\n{query}\"\n",
    "    try:\n",
    "        return llm(prompt)\n",
    "    except Exception as e:\n",
    "        return f\"LLM fallback failed: {str(e)}\"\n",
    "\n",
    "llm_fallback = Tool(\n",
    "    name=\"Groq LLM Fallback\",\n",
    "    func=answer_with_llm,\n",
    "    description=\"If web search fails, answer with your own knowledge.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8ff2d",
   "metadata": {},
   "source": [
    "### Initializing the Agent\n",
    "\n",
    "The agent will:\n",
    "- Try web search first\n",
    "- If results are insufficient or an error occurs, fallback to the LLM for an answer\n",
    "\n",
    "We use LangChain's AgentType.ZERO_SHOT_REACT_DESCRIPTION for tool selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [web_search, llm_fallback]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6206e84",
   "metadata": {},
   "source": [
    "### Testing the Agent\n",
    "\n",
    "first query:\n",
    "- Standard Web search on latest RAG research\n",
    "- One tool call should be enough\n",
    "  \n",
    "Second query:\n",
    "- Difference between a unicorn and time travelling fridge in machine learning\n",
    "- Forces an LLM call directly without calling the search API because it can see that these concepts are made up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80fae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Standard Web Search ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the latest research on retrieval augmented generation in 2024, I should first attempt to search the web for relevant information.\n",
      "\n",
      "Action: DuckDuckGo Web Search\n",
      "Action Input: retrieval augmented generation 2024 research\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWikipedia Retrieval-augmented generation - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n",
      "3 days ago - Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information . With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM's ...\n",
      "\n",
      "[2312.10997] Retrieval - Augmented Generation for Large Language...\n",
      "https://arxiv.org/abs/2312.10997\n",
      "Retrieval - Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases.View a PDF of the paper titled Retrieval - Augmented Generation for Large Language Models: A Survey, by Yunfan Gao and 8 other authors.\n",
      "\n",
      "Unlocking the Power of Retrieval - Augmented Generation ... | Medium\n",
      "https://medium.com/@sayalikhot21/unlocking-the-power-of-retrieval-augmented-generation-rag-use-cases-benefits-and-more-a8119b1ab7dc\n",
      "This is where Retrieval - Augmented Generation (RAG) comes into play. RAG enhances generative models by combining their power with external information retrieval systems, effectively addressing many of these limitations.\n",
      "\n",
      "Eliciting In-context Retrieval and Reasoning for Long-Context...\n",
      "https://machinelearning.apple.com/research/eliciting-in-context\n",
      "Context Tuning for Retrieval Augmented Generation . Retrieval Augmented Generation (RAG) addresses this problem by retrieving a list of relevant tools for a given task. However, RAG's tool retrieval step requires all the required information to be explicitly present in the query.\n",
      "\n",
      "A Survey on RAG Meeting LLMs: Towards Retrieval - Augmented ...\n",
      "https://scispace.com/papers/a-survey-on-rag-meeting-llms-towards-retrieval-augmented-n4rx46xopyux\n",
      "(DOI: 10.1145/3637528.3671470) As one of the most advanced techniques in AI, Retrieval - Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks.\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt appears that the search results provide a good overview of the concept of retrieval augmented generation (RAG) and its applications. However, the results do not specifically focus on the latest research in 2024. To find more up-to-date information, I should try to search again with a more specific query.\n",
      "\n",
      "Action: DuckDuckGo Web Search\n",
      "Action Input: 2024 research papers on retrieval augmented generation\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2024 : The Year of RAG (Part 1). At Tenfold Growth This Year... | Medium\n",
      "https://medium.com/@yu-joshua/2024-the-year-of-rag-part-1-bdf8a05f818d\n",
      "2024 has made a start of an unprecedented surge in research on Retrieval - Augmented Generation (RAG). A quick search on arXiv reveals a staggering 1,202 papers published in 2024 alone, dwarfing the 93 that appeared in 2023 and the mere 10 in 2022.\n",
      "\n",
      "A Survey on Knowledge-Oriented Retrieval - Augmented Generation\n",
      "https://arxiv.org/pdf/2503.10677\n",
      "Additional Key Words and Phrases: Information Retrieval , Retrieval - augmented Generation , Large Language Model. 2024 . Retrieval - Augmented . Generation with Knowledge Graphs for Customer Service Question Answering.\n",
      "\n",
      "Benchmarking Retrieval - Augmented Generation for Medicine ( 2024 )\n",
      "https://scispace.com/papers/benchmarking-retrieval-augmented-generation-for-medicine-4tusr6e3e9\n",
      "Retrieval - augmented generation (RAG) is a promising solution and has been widely adopted.The paper examines quantifiable metrics of the Retrieval and Generation component, discusses limitations of current benchmarks, and proposes potential directions for further research .\n",
      "\n",
      "Published as a conference paper at ICLR 2024\n",
      "https://openreview.net/pdf?id=w4DW6qkRmt\n",
      "Constructing these retrieval - augmented LLMs typically involves additional fine-tuning (Borgeaud et al., 2022; Izacard et al., 2023), but it becomes infeasible due to the increase in scale and the recent nature of black-box API (OpenAI, 2023).\n",
      "\n",
      "Trustworthy Alignment of Retrieval - Augmented Large Language...\n",
      "https://proceedings.mlr.press/v235/zhang24bg.html\n",
      "In this paper , we focus on the trustworthiness of language models with respect to retrieval augmentation . Despite being supported with external evidence, retrieval - augmented generation still suffers from hallucinations, one primary cause of which is the conflict between contextual...\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: The latest research on retrieval augmented generation in 2024 includes a wide range of studies and papers published on arXiv, Medium, and other academic platforms. Some of the key findings and topics include the application of RAG in medicine, customer service question answering, and the trustworthiness of language models with respect to retrieval augmentation. According to a Medium article, 2024 has seen an unprecedented surge in research on RAG, with over 1,202 papers published on arXiv alone. Other papers have explored the use of RAG in specific domains, such as medicine, and have proposed new benchmarks and evaluation metrics for RAG systems. Overall, the research in 2024 suggests that RAG is a rapidly evolving field with significant potential for improving the performance and trustworthiness of large language models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest research on retrieval augmented generation in 2024 includes a wide range of studies and papers published on arXiv, Medium, and other academic platforms. Some of the key findings and topics include the application of RAG in medicine, customer service question answering, and the trustworthiness of language models with respect to retrieval augmentation. According to a Medium article, 2024 has seen an unprecedented surge in research on RAG, with over 1,202 papers published on arXiv alone. Other papers have explored the use of RAG in specific domains, such as medicine, and have proposed new benchmarks and evaluation metrics for RAG systems. Overall, the research in 2024 suggests that RAG is a rapidly evolving field with significant potential for improving the performance and trustworthiness of large language models.\n",
      "\n",
      "=== Test 2: Obscure Query (forces LLM Fallback) ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The question seems to be asking for a comparison between two concepts that don't appear to be related to each other in a straightforward manner. \"Unicorn\" is a mythical creature, while \"time-traveling refrigerator\" is a fictional concept that doesn't exist in reality. In the context of machine learning, I'm not aware of any direct connection between these two concepts. However, I can try to provide an explanation by using analogies or metaphors related to machine learning.\n",
      "\n",
      "Action: Groq/Gemini LLM Fallback\n",
      "Action Input: Explain the difference between a unicorn and a time-traveling refrigerator in machine learning.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mLLM fallback failed: 'str' object has no attribute 'content'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: It seems the LLM fallback failed to provide a meaningful response. This could be due to the highly abstract and unrelated nature of the concepts \"unicorn\" and \"time-traveling refrigerator\" in the context of machine learning. Given this failure, I should attempt to craft a response based on my understanding of machine learning concepts and how these fictional elements might metaphorically relate to them.\n",
      "\n",
      "Action: Groq/Gemini LLM Fallback\n",
      "Action Input: Use metaphors to explain machine learning concepts with unicorn and time-traveling refrigerator.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mLLM fallback failed: 'str' object has no attribute 'content'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: It appears that the LLM fallback is not providing a useful response, likely due to the unusual nature of the question. I will attempt to craft a response based on my general knowledge of machine learning and the concepts of \"unicorn\" and \"time-traveling refrigerator\" as metaphors.\n",
      "\n",
      "In machine learning, a \"unicorn\" could represent a highly idealized or mythical model that performs exceptionally well but is difficult to achieve in practice. This could be analogous to the mythical creature, which is often depicted as rare and extraordinary. On the other hand, a \"time-traveling refrigerator\" could be seen as a metaphor for a model that can adapt to different time periods or datasets, much like how a time-traveling refrigerator might be able to transport goods across different points in time. However, this concept is purely fictional and not grounded in reality, much like the idea of a time-traveling refrigerator.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The difference between a unicorn and a time-traveling refrigerator in machine learning is that a unicorn represents a highly idealized model that performs exceptionally well but is difficult to achieve, while a time-traveling refrigerator is a purely fictional concept that could metaphorically represent a model that adapts to different time periods or datasets, but is not grounded in reality.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The difference between a unicorn and a time-traveling refrigerator in machine learning is that a unicorn represents a highly idealized model that performs exceptionally well but is difficult to achieve, while a time-traveling refrigerator is a purely fictional concept that could metaphorically represent a model that adapts to different time periods or datasets, but is not grounded in reality.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test 1: Standard Web Search ===\")\n",
    "response1 = agent.run(\"Latest research on retrieval augmented generation in 2024\")\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n=== Test 2: Obscure Query (forces LLM Fallback) ===\")\n",
    "response2 = agent.run(\"Explain the difference between a unicorn and a time-traveling refrigerator in machine learning.\")\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfaac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
